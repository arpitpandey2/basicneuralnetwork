{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNc8x9XRtbE016riIXly0jB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arpitpandey2/basicneuralnetwork/blob/main/basicneuralnetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "azfQgEyfHJi6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our model\n",
        "class Model(nn.Module):\n",
        "  def __init__(self,in_features=4,h1=8,h2=9,out_features=3):\n",
        "    super().__init__()\n",
        "    self.fc1= nn.Linear(in_features,h1)\n",
        "    self.fc2= nn.Linear(h1,h2)\n",
        "    self.out= nn.Linear(h2,out_features)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x= f.relu(self.fc1(x))\n",
        "    x= f.relu(self.fc2(x))\n",
        "    x= self.out(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "KTU3RuqWHn-O"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feed the data\n",
        "torch.manual_seed(30)\n",
        "mode1= Model()"
      ],
      "metadata": {
        "id": "pFavDYwdJraM"
      },
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "url= 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n",
        "my_df= pd.read_csv(url)\n",
        "my_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xiUr7nNWIi4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace objects to numbers, so to train easily\n",
        "my_df['species']=my_df['species'].replace('setosa',0.0)\n",
        "my_df['species']=my_df['species'].replace('versicolor',1.0)\n",
        "my_df['species']=my_df['species'].replace('virginica',2.0)\n",
        "my_df['species'] = my_df['species'].astype(int)\n",
        "my_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pM2LwejvKtNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for splitting\n",
        "X=my_df.drop('species',axis=1)\n",
        "Y=my_df['species']\n",
        "x=X.values\n",
        "y=Y.values"
      ],
      "metadata": {
        "id": "KpMyjL-DL3ui"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x\n",
        "y"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Du2bjHVmMgr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "OQ-Odo8oMzeV"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2, random_state=40)"
      ],
      "metadata": {
        "id": "mO-OEHr5PkIm"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "x_train=torch.FloatTensor(x_train)\n",
        "x_test=torch.FloatTensor(x_test)\n",
        "\n",
        "y_train=torch.LongTensor(y_train)\n",
        "y_test=torch.LongTensor(y_test)"
      ],
      "metadata": {
        "id": "f7bjGBzGQCR1"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define criterion and optimizer\n",
        "criterion= nn.CrossEntropyLoss()\n",
        "optimizer= torch.optim.Adam(mode1.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "NoCP2YICQocJ"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs=100\n",
        "losses=[]\n",
        "for i in range(epochs):\n",
        "  y_pred= mode1.forward(x_train)\n",
        "  loss= criterion(y_pred,y_train)\n",
        "  losses.append(loss.detach().numpy())\n",
        "\n",
        "  if i%10==0:\n",
        "    print(f\"Epoch: {i} and loss {loss}\")\n",
        "\n",
        "  # Backprop and optimize\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "Iay7BTLERRRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss\n",
        "plt.plot(range(epochs),losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')"
      ],
      "metadata": {
        "id": "pMUrRxlkXY3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_eval= mode1.forward(x_test)\n",
        "  loss= criterion(y_eval,y_test)\n",
        "loss"
      ],
      "metadata": {
        "id": "lxL0UvYUc32g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct= 0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(x_test):\n",
        "    y_val= mode1.forward(data)\n",
        "    print(f'{i+1:2}. {str(y_val):38} {y_test[i]}')\n",
        "    if y_val.argmax().item()== y_test[i]:\n",
        "      correct+=1\n",
        "\n",
        "print(f'total corrects are {correct}')"
      ],
      "metadata": {
        "id": "zeZEUaK2dg88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "New data and check our neural network"
      ],
      "metadata": {
        "id": "0o2l-yIZgeAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_iris= torch.tensor([4.7,3.2,1.3,0.3])"
      ],
      "metadata": {
        "id": "kEz5tA-1gcw7"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  print(mode1(new_iris))\n",
        "  print(mode1(new_iris).argmax().item())\n",
        ""
      ],
      "metadata": {
        "id": "I1fX1dJlg_p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save and check our model"
      ],
      "metadata": {
        "id": "BUJVXlvXizdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(mode1.state_dict(), 'my_iris_model.pth')\n"
      ],
      "metadata": {
        "id": "BV9Qa3cMh5RR"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "loaded_model = Model()\n",
        "loaded_model.load_state_dict(torch.load('my_iris_model.pth'))\n",
        "\n",
        "# Test the loaded model with new data\n",
        "new_iris_test = torch.tensor([4.7,3.2,1.3,0.3])\n",
        "with torch.no_grad():\n",
        "  print(loaded_model(new_iris_test))\n",
        "  print(loaded_model(new_iris_test).argmax().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5eHL72sikuS",
        "outputId": "39c33f7c-84b2-4173-dbc0-bed6ee343198"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11.2693,  5.2038, -9.6135])\n",
            "0\n"
          ]
        }
      ]
    }
  ]
}